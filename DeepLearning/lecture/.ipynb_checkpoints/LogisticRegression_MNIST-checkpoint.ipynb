{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow load complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # 행렬 계산 라이브러리\n",
    "import matplotlib.pyplot as pit # 그래프 보여주는 라이브러리\n",
    "import scipy # 행렬 계산 라이브러리\n",
    "import tensorflow as tf   # 텐서플로우 라이브러리\n",
    "print \"tensorflow load complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data  # 텐서플로우에서 기본제공하는 MNIST(숫자필기체, 1만개) 데이터입니다\n",
    "mnist = input_data.read_data_sets('data/', one_hot=True) # OneHot Coding 이란, 정답 라벨 하나당 비트 하나를 할당하는것을 말합니다\n",
    "trainimg = mnist.train.images # 학습할 이미지\n",
    "trainlabel = mnist.train.labels # 학습할 라벨\n",
    "testimg = mnist.test.images # 테스트할 이미지\n",
    "testlabel = mnist.test.labels # 테스트할 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01 # W를 Optimize 1회 할때, 가중치 비율 \n",
    "training_epochs = 50  # 전체 학습 데이터에 대해서 총 반복학습 횟수\n",
    "batch_size = 100  # 10,000개 데이터 중에 한번에 몇개를 가져와서 Optimize 할것인가\n",
    "display_step = 1 # 몇번째 Epoch 마다 성능을 리포트 할것인가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network constructed\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(\"float\", [None, 784])\n",
    "y = tf.placeholder(\"float\", [None, 10])\n",
    "\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "actv = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(actv), reduction_indices=1))\n",
    "\n",
    "optm = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "pred = tf.equal(tf.argmax(actv, 1), tf.argmax(y, 1))\n",
    "accr = tf.reduce_mean(tf.cast(pred, \"float\"))\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "print \"network constructed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000/050 cost: 1.178933608 train_acc: 0.850\n",
      "Epoch: 001/050 cost: 0.662358132 train_acc: 0.840\n",
      "Epoch: 002/050 cost: 0.551221489 train_acc: 0.850\n",
      "Epoch: 003/050 cost: 0.499617441 train_acc: 0.890\n",
      "Epoch: 004/050 cost: 0.465458250 train_acc: 0.890\n",
      "Epoch: 005/050 cost: 0.442432747 train_acc: 0.880\n",
      "Epoch: 006/050 cost: 0.422509842 train_acc: 0.880\n",
      "Epoch: 007/050 cost: 0.412277417 train_acc: 0.850\n",
      "Epoch: 008/050 cost: 0.400218941 train_acc: 0.890\n",
      "Epoch: 009/050 cost: 0.390572505 train_acc: 0.900\n",
      "Epoch: 010/050 cost: 0.380997064 train_acc: 0.850\n",
      "Epoch: 011/050 cost: 0.370854006 train_acc: 0.840\n",
      "Epoch: 012/050 cost: 0.371149783 train_acc: 0.920\n",
      "Epoch: 013/050 cost: 0.364784412 train_acc: 0.940\n",
      "Epoch: 014/050 cost: 0.361259482 train_acc: 0.950\n",
      "Epoch: 015/050 cost: 0.359030745 train_acc: 0.900\n",
      "Epoch: 016/050 cost: 0.360001264 train_acc: 0.920\n",
      "Epoch: 017/050 cost: 0.353636126 train_acc: 0.910\n",
      "Epoch: 018/050 cost: 0.341860959 train_acc: 0.930\n",
      "Epoch: 019/050 cost: 0.342172148 train_acc: 0.880\n",
      "Epoch: 020/050 cost: 0.336715219 train_acc: 0.890\n",
      "Epoch: 021/050 cost: 0.332708695 train_acc: 0.850\n",
      "Epoch: 022/050 cost: 0.335676576 train_acc: 0.900\n",
      "Epoch: 023/050 cost: 0.335770668 train_acc: 0.910\n",
      "Epoch: 024/050 cost: 0.334577433 train_acc: 0.930\n",
      "Epoch: 025/050 cost: 0.328166434 train_acc: 0.900\n",
      "Epoch: 026/050 cost: 0.320133711 train_acc: 0.910\n",
      "Epoch: 027/050 cost: 0.323591674 train_acc: 0.920\n",
      "Epoch: 028/050 cost: 0.328321510 train_acc: 0.910\n",
      "Epoch: 029/050 cost: 0.324219859 train_acc: 0.890\n",
      "Epoch: 030/050 cost: 0.325200242 train_acc: 0.880\n",
      "Epoch: 031/050 cost: 0.321693996 train_acc: 0.950\n",
      "Epoch: 032/050 cost: 0.318428297 train_acc: 0.930\n",
      "Epoch: 033/050 cost: 0.313628107 train_acc: 0.900\n",
      "Epoch: 034/050 cost: 0.320474593 train_acc: 0.900\n",
      "Epoch: 035/050 cost: 0.313783317 train_acc: 0.920\n",
      "Epoch: 036/050 cost: 0.311299157 train_acc: 0.910\n",
      "Epoch: 037/050 cost: 0.320011965 train_acc: 0.920\n",
      "Epoch: 038/050 cost: 0.312628700 train_acc: 0.950\n",
      "Epoch: 039/050 cost: 0.315609011 train_acc: 0.960\n",
      "Epoch: 040/050 cost: 0.305672760 train_acc: 0.940\n",
      "Epoch: 041/050 cost: 0.316579948 train_acc: 0.920\n",
      "Epoch: 042/050 cost: 0.311475591 train_acc: 0.950\n",
      "Epoch: 043/050 cost: 0.308252584 train_acc: 0.870\n",
      "Epoch: 044/050 cost: 0.304463395 train_acc: 0.920\n",
      "Epoch: 045/050 cost: 0.309485745 train_acc: 0.900\n",
      "Epoch: 046/050 cost: 0.308645338 train_acc: 0.900\n",
      "Epoch: 047/050 cost: 0.301057787 train_acc: 0.880\n",
      "Epoch: 048/050 cost: 0.303983920 train_acc: 0.950\n",
      "Epoch: 049/050 cost: 0.304246395 train_acc: 0.960\n",
      "Optimization Finished!\n",
      "Accuracy :  0.9187\n",
      "Done. \n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        num_batch = int(mnist.train.num_examples/batch_size)\n",
    "        for i in range(num_batch):\n",
    "            if 0:\n",
    "                batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            else:\n",
    "                randidx = np.random.randint(trainimg.shape[0], size = batch_size)\n",
    "                batch_xs = trainimg[randidx, :]\n",
    "                batch_ys = trainlabel[randidx, :]\n",
    "            sess.run(optm, feed_dict={x:batch_xs, y:batch_ys})\n",
    "            avg_cost += sess.run(cost, feed_dict={x:batch_xs, y:batch_ys})/num_batch\n",
    "            \n",
    "        if epoch % display_step == 0:\n",
    "            train_acc = accr.eval({x:batch_xs, y:batch_ys})\n",
    "            print (\"Epoch: %03d/%03d cost: %.9f train_acc: %.3f\"\n",
    "                  % (epoch, training_epochs, avg_cost, train_acc))\n",
    "    print \"Optimization Finished!\"\n",
    "    print \"Accuracy : \", accr.eval({x:mnist.test.images, y:mnist.test.labels})\n",
    "print \"Done. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
